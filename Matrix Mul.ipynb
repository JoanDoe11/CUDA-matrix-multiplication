{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Matrix Mul.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMHsSX87KXhJ3cnv6AlHFmZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2UmnfFmP9Ykf","colab_type":"text"},"source":["Initializing:"]},{"cell_type":"code","metadata":{"id":"7hIfzCGF8vZy","colab_type":"code","colab":{}},"source":["import numpy\n","import random\n","#!pip install pycuda\n","import pycuda.driver as cuda\n","import pycuda.autoinit\n","from pycuda.compiler import SourceModule"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wf6NJKPsGssn","colab_type":"text"},"source":["Matrix initialization and util functions:\n","\n","Matrices are square."]},{"cell_type":"code","metadata":{"id":"OZiVQaUPGrf4","colab_type":"code","colab":{}},"source":["global m1\n","global m2\n","global height1\n","global height2\n","global width1\n","global width2\n","global res \n","\n","height1 = 4\n","width1 = 4\n","height2 = 4\n","width2 = 4\n","\n","m1 = numpy.zeros((height1,width1)).astype(numpy.int32)\n","m2 = numpy.zeros((height2,width2)).astype(numpy.int32)\n","res = numpy.zeros((height1,width2)).astype(numpy.int32)\n","\n","for i in range(height1):\n","  for j in range(width1):\n","    m1[i][j] = random.randrange(0, 10)\n","\n","for i in range(height2):\n","  for j in range(width2):\n","    m2[i][j] = random.randrange(0, 10)\n","\n","def print_matrix(matrix):\n","  for i in range(len(matrix)):\n","    for j in range(len(matrix[i])):\n","        print(matrix[i][j],end = \"  \")\n","    print(\"\\n\")\n","\n","def matrix_mul(matrix1,matrix2):\n","  return matrix1.dot(matrix2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Xnav2InfemD","colab_type":"text"},"source":["# CUDA kernel\n","Matrix multiplication using CUDA shared memory. All threads of a block copy the needed matrix chunks into shared memory for their block and then proceed to work from there."]},{"cell_type":"code","metadata":{"id":"IELvSeSugJmH","colab_type":"code","colab":{}},"source":["mod = SourceModule(\"\"\"\n","     __global__ void multiplyMatrix(int *m1, int *m2, int *res, int width){\n","       \n","       #define TILE 2\n","\n","       __shared__ int m1shared[TILE][TILE];\n","       __shared__ int m2shared[TILE][TILE];\n","\n","       int col = blockIdx.x * TILE + threadIdx.x;\n","       int row = blockIdx.y * TILE + threadIdx.y;\n","       int idx = row*width + col;\n","\n","       int range = (width / TILE) + ((width % TILE) != 0);\n","\n","       \n","          int val = 0;\n","          \n","          for(int i = 0; i<range; ++i){\n","            if (row < width && i*TILE+threadIdx.x < width)\n","             m1shared[threadIdx.y][threadIdx.x] = m1[row*width+(i*TILE + threadIdx.x)];\n","            else\n","             m1shared[threadIdx.y][threadIdx.x] = 0;\n","            if (col < width && i*TILE+threadIdx.y < width)\n","             m2shared[threadIdx.y][threadIdx.x] = m2[(i*TILE + threadIdx.y)*width + col];\n","            else\n","             m2shared[threadIdx.y][threadIdx.x] = 0;\n","            \n","            __syncthreads();\n","          \n","            for(int j=0; j<TILE; ++j){\n","                val += m1shared[threadIdx.y][j]*m2shared[j][threadIdx.x];\n","            }\n","          \n","            __syncthreads();\n","          \n","          }\n","\n","          if( (row < width) && (col < width))\n","        {\n","          res[idx] = val;\n","        }\n","     }\n","   \"\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GfOK_4ujjzqU","colab_type":"text"},"source":["Main:"]},{"cell_type":"code","metadata":{"id":"n00JhuFXj0j-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":598},"outputId":"dd97137c-ad18-4dea-c1d2-c3b85fdcf705","executionInfo":{"status":"ok","timestamp":1582203113633,"user_tz":-60,"elapsed":1042,"user":{"displayName":"Jovana Atanasijevic","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD7w_KlIqOvrfIVeh5q8dNAvrQp1lSjviwtmCvO=s64","userId":"05339616586287024812"}}},"source":["print_matrix(m1)\n","print_matrix(m2)\n","\n","m1_gpu = cuda.mem_alloc(m1.nbytes)\n","m2_gpu = cuda.mem_alloc(m2.nbytes)\n","res_gpu = cuda.mem_alloc(res.nbytes)\n","\n","cuda.memcpy_htod(m1_gpu, m1)\n","cuda.memcpy_htod(m2_gpu, m2)\n","cuda.memcpy_htod(res_gpu, res)\n","\n","# tiles - we divide the matrix into tiles\n","t_width = 2\n","\n","# kernel\n","func = mod.get_function(\"multiplyMatrix\")\n","func(m1_gpu, m2_gpu, res_gpu, numpy.int32(width1), block=(t_width,t_width,1), grid=(4, 4, 1))\n","\n","cuda.memcpy_dtoh(res, res_gpu)\n","\n","print_matrix(res)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["7  5  8  2  \n","\n","1  2  0  4  \n","\n","0  3  8  8  \n","\n","3  3  5  1  \n","\n","4  0  7  6  \n","\n","2  0  9  2  \n","\n","6  6  2  6  \n","\n","5  1  5  6  \n","\n","96  50  120  112  \n","\n","28  4  45  34  \n","\n","94  56  83  102  \n","\n","53  31  63  60  \n","\n","96  50  120  112  \n","\n","28  4  45  34  \n","\n","94  56  83  102  \n","\n","53  31  63  60  \n","\n"],"name":"stdout"}]}]}